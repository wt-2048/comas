parallel_loading: false
agent_workflow: comas
workflow_version: old
shared_agents: false
credit_ref_num_nodes: 1
credit_ref_num_gpus_per_node: 8
credit_num_nodes: 1
credit_num_gpus_per_node: 8
colocate_credit_ref: false
credit_beta: 0.05
credit_granularity: token
credit_nll_loss: false
credit_nll_loss_coef: 0.0
credit_grad_clip: 10.0
credit_adam_betas:
- 0.9
- 0.95
credit_l2: 0.0
credit_score_type: process
credit_learning_rate: 1.0e-06
credit_pretrain: null
credit_scheduler: constant_with_warmup
credit_lr_warmup_ratio: 0.0
credit_batch_norm: false
credit_model: null
warmup_steps_for_credit: -1
credit_score_coef: 1.0
verifier_score_coef: 1.0
reward_alloc:
  name: null
  alpha: 0.5
  beta: 0.5
  use_ttrl: false
mask_truncated_completions: false
default_agent:
  pg_strategy: SPREAD
  role: base
  is_reasoning_model: false
  enable_thinking: false
  is_tuning: true
  pretrain: null
  reward_pretrain: null
  remote_rm_url: null
  critic_pretrain: null
  value_head_prefix: score
  ref_reward_offload: false
  ref_num_nodes: 1
  ref_num_gpus_per_node: 8
  reward_num_nodes: 1
  reward_num_gpus_per_node: 8
  colocate_actor_ref: false
  colocate_all_models: false
  actor_num_nodes: 1
  actor_num_gpus_per_node: 8
  critic_num_nodes: 1
  critic_num_gpus_per_node: 8
  colocate_critic_reward: false
  vllm_num_engines: 4
  vllm_tensor_parallel_size: 1
  vllm_sync_backend: gloo
  vllm_gpu_memory_utilization: 0.9
  vllm_enable_sleep: false
  deepspeed_enable_sleep: false
  enable_prefix_caching: false
  enforce_eager: false
  eval_steps: -1
  logging_steps: 1
  save_steps: -1
  ckpt_path: ./ckpt/checkpoints_ppo_ray
  max_ckpt_num: 3
  max_ckpt_mem: 100000000
  load_checkpoint: false
  local_rank: -1
  zero_stage: 2
  gradient_checkpointing: false
  bf16: false
  enable_ema: false
  zpg: 1
  adam_offload: false
  actor_init_on_gpu: false
  flash_attn: false
  grad_accum_dtype: null
  disable_trace_cache: false
  gradient_checkpointing_use_reentrant: false
  disable_fast_tokenizer: false
  load_in_4bit: false
  lora_rank: 0
  lora_alpha: 16
  target_modules: all-linear
  lora_dropout: 0.0
  save_path: ./ckpt
  num_episodes: 1
  rollout_batch_size: 1024
  micro_rollout_batch_size: 8
  max_epochs: 1
  max_len: null
  prompt_max_len: 1024
  generate_max_len: 1024
  truncate_prompt: false
  max_samples: 100000000
  max_norm: 1.0
  l2: 0.0
  ptx_coef: 0.05
  eps_clip: 0.2
  value_clip: 0.2
  lambd: 0.95
  gamma: 1
  micro_train_batch_size: 4
  train_batch_size: 128
  normalize_reward: false
  top_p: 1.0
  temperature: 1.0
  eval_temperature: 0.0
  seed: 42
  freezing_actor_steps: -1
  n_samples_per_prompt: 1
  save_value_network: false
  use_kl_loss: false
  actor_learning_rate: 1.0e-06
  critic_learning_rate: 9.0e-06
  lr_warmup_ratio: 0.03
  kl_target: null
  init_kl_coef: 0.01
  use_kl_estimator_k3: false
  aux_loss_coef: 0.0
  adam_betas:
  - 0.9
  - 0.95
  reward_clip_range:
  - -10
  - 10
  advantage_estimator: gae
  training_mode: rl
  eos_token_id: null
packing_samples: false
extra_eval_tasks: null
extra_eval_dir: null
verify_task: math
verify_task_eval: math
filter_samples_by_reward: false
prompt_data: null
prompt_data_probs: '1.0'
prompt_split: train
pretrain_data: null
pretrain_data_probs: '1.0'
pretrain_split: train
input_key: input
label_key: label
output_key: output
add_think_token: 0
add_prompt_suffix: '


  Please reason step by step, and put your final answer within \boxed{}.'
input_template: null
apply_chat_template: false
use_wandb: null
wandb_mode: offline
wandb_key: null
wandb_path: null
wandb_org: null
wandb_group: null
wandb_project: marti_train_ppo
wandb_run_name: null
use_tensorboard: null
perf: false
workflow_args:
  template_id: -1
  num_rounds: 2
  num_references: 2
agents:
- agent-0:
    pretrain: /mnt/user/model/qwen2.5-3b-instruct
- agent-1:
    pretrain: /mnt/user/model/qwen2.5-3b-instruct
- agent-2:
    pretrain: /mnt/user/model/qwen2.5-3b-instruct
- agent-3:
    pretrain: /mnt/user/model/qwen2.5-3b-instruct
